{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0726a269-ac25-4062-8968-3a148a9c50a6",
   "metadata": {},
   "source": [
    "# **Diagnóstico Automatizado de Linfomas Malignos en Biopsias H&E mediante Aprendizaje Automático**\n",
    "## *Aftab Ahmed Choudhry*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3f7146-9352-49fd-a642-05ea72740dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications import InceptionV3, MobileNetV2, DenseNet201, EfficientNetV2B0, ResNet50V2, VGG16 \n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense, Dropout, RandomFlip, RandomRotation, RandomZoom, RandomTranslation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import seaborn as sns\n",
    "from itertools import cycle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f3e7a5-0ddf-4974-bd45-69fd3a87b8de",
   "metadata": {},
   "source": [
    "## ***Conversión Única de Imágenes .tif a .png***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9604e547-afe7-4057-af9a-b8ade2c9f0b1",
   "metadata": {},
   "source": [
    "Esta celda se ejecuta **una sola vez** para convertir las imágenes originales descargadas desde Kaggle (en formato `.tif`) al formato `.png`, ya que `image_dataset_from_directory()` de TensorFlow **no soporta `.tif`**. Tras la conversión, las imágenes `.tif` se eliminan automáticamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91552266-4d6c-4e19-b67e-5591f71ebd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = './dataset'\n",
    "\n",
    "for class_name in ['CLL', 'FL', 'MCL']:\n",
    "    folder = os.path.join(base_path, class_name)\n",
    "    tif_files = glob.glob(os.path.join(folder, '*.tif'))\n",
    "    png_files = glob.glob(os.path.join(folder, '*.png'))\n",
    "\n",
    "    if len(png_files) > 0:\n",
    "        print(f\"Conversión ya realizada para la clase {class_name}. Se omite.\")\n",
    "        continue\n",
    "\n",
    "    for tif_path in tif_files:\n",
    "        with Image.open(tif_path) as img:\n",
    "            rgb_img = img.convert('RGB')\n",
    "            new_path = tif_path.replace('.tif', '.png')\n",
    "            rgb_img.save(new_path)\n",
    "\n",
    "        os.remove(tif_path)\n",
    "    \n",
    "    print(f\"Conversión completada para la clase {class_name}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cd8dc8-f630-45b2-bb56-e39da0997867",
   "metadata": {},
   "source": [
    "## *Verificación de disponibilidad de GPU*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3560d506-51d3-43b3-8e9d-04255f21dedf",
   "metadata": {},
   "source": [
    "Esta celda comprueba si TensorFlow detecta una GPU en el entorno actual. Es útil para confirmar que la aceleración por hardware está activa y que se aprovechará la GPU durante el entrenamiento del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e74b92-d37c-4a9a-b571-1c75f56ee7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))\n",
    "print(tf.test.is_gpu_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef215e75-aea9-4271-80b3-c016d1a414e3",
   "metadata": {},
   "source": [
    "## Preproceso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec09d35e-1fd0-4654-abdf-4a4ab407d61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy_loss(history):\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Model Accuracy Over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Model Loss Over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731db220-a293-4557-bd30-52ab99cbb8d7",
   "metadata": {},
   "source": [
    "### Carga de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bfdd11-bf2f-4bb5-bb16-310a945377b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = './dataset'\n",
    "image_size = (224, 224)\n",
    "\n",
    "dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    dataset_path,\n",
    "    image_size = image_size,\n",
    "    shuffle = True,\n",
    "    seed = 23\n",
    ")\n",
    "\n",
    "class_names = dataset.class_names\n",
    "print(\"Classes:\", class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf6d359-99b1-40ff-9ae5-69446b567547",
   "metadata": {},
   "source": [
    "### Visualización básica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ab994c-91e7-45c4-85a8-80879a1f6ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "for images, labels in dataset.take(1):\n",
    "    print(\"Image batch shape:\", images.shape)\n",
    "    print(\"Label batch shape:\", labels.shape)\n",
    "\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(f\"Label: {labels[i].numpy()} ({class_names[labels[i].numpy()]})\")\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccccb14a-ed62-4d7c-a36e-f5b9e10f2101",
   "metadata": {},
   "source": [
    "### Partición del conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ab2541-f9b2-4a7a-9226-f6e07a407164",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for images, labels in dataset:\n",
    "    X.append(images.numpy())\n",
    "    y.append(labels.numpy())\n",
    "\n",
    "X = np.concatenate(X)\n",
    "y = np.concatenate(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=23, stratify=y)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71141655-5b93-436d-9a91-ed7783f70bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=23, stratify=y_test)\n",
    "\n",
    "print(\"Train:\", X_train.shape, y_train.shape)\n",
    "print(\"Validation:  \", X_val.shape, y_val.shape)\n",
    "print(\"Test: \", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f50fcee-c248-4451-ae63-dd491376acca",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "X_train_flattened = X_train.reshape(X_train.shape[0], -1)\n",
    "df_train = pd.DataFrame(X_train_flattened)\n",
    "df_train['target'] = y_train\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea0a239-b233-4b43-b6c8-5529453f49e7",
   "metadata": {},
   "source": [
    "Reordenaremos las columnas de manera que la variable target sea la primera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f3dbe1-dedc-4d17-a382-1116dd767188",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "cols = list(df_train.columns)\n",
    "cols.remove('target')\n",
    "cols.insert(0,'target')\n",
    "df_train = df_train.reindex(columns=cols)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cb39f9-200c-4382-8255-1a873555e37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train.iloc[:, :1000].describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bf511d-94dc-4043-bfd6-4af8db08c9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3100c6e-436c-45ef-bed1-06a63e3b6bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmenter = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "augmentations_per_image = 3\n",
    "\n",
    "X_augmented = []\n",
    "y_augmented = []\n",
    "\n",
    "for img, label in zip(X_train, y_train):\n",
    "    img = np.expand_dims(img, 0)\n",
    "    aug_iter = augmenter.flow(img, batch_size=1)\n",
    "    for _ in range(augmentations_per_image):\n",
    "        aug_img = next(aug_iter)[0].astype(np.uint8)\n",
    "        X_augmented.append(aug_img)\n",
    "        y_augmented.append(label)\n",
    "\n",
    "X_augmented = np.array(X_augmented)\n",
    "y_augmented = np.array(y_augmented)\n",
    "\n",
    "X_train_augmented = np.concatenate([X_train, X_augmented])\n",
    "y_train_augmented = np.concatenate([y_train, y_augmented])\n",
    "\n",
    "print(\"Original training set size:\", X_train.shape)\n",
    "print(\"Augmented training set size:\", X_train_augmented.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638417c2-d259-4947-a33b-8402d8d76581",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = Sequential([\n",
    "    RandomFlip(),\n",
    "    RandomRotation(0.1),\n",
    "    RandomZoom(0.1),\n",
    "    RandomTranslation(0.1, 0.1)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608dc6f7-e894-4533-a155-fa491b59a45d",
   "metadata": {},
   "source": [
    "## Entrenar la CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c82ae7-4904-4ab1-bbbe-151c7ffe0082",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1645ac-9957-4221-b235-208f8835d582",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [ModelCheckpoint('best_model.h5', monitor = 'val_accuracy', save_best_only = True, verbose = 1),\n",
    "             ReduceLROnPlateau(monitor = 'val_accuracy', patience = 4, factor = 0.1, verbose = 1, min_lr = 1e-6),\n",
    "             EarlyStopping(monitor = 'val_accuracy', patience = 5, verbose = 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9010a84-56fa-4f76-85cc-f36bee059eaf",
   "metadata": {},
   "source": [
    "### InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd138d9-220f-4a4f-8e17-f0d0b75384e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "inceptionV3_base_model = InceptionV3(include_top = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb1359a-c9ab-4803-91b6-7c231fabf213",
   "metadata": {},
   "source": [
    "#### Freeze and Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45d010b-b66f-4ec8-91d0-2848a09ea56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inceptionV3_base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5af42b-0462-4cd5-934d-0822304d43dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "inceptionV3_inputs = Input(shape = (224, 224, 3))\n",
    "\n",
    "# inceptionV3_x = data_augmentation(inceptionV3_inputs)\n",
    "\n",
    "inceptionV3_x = tf.keras.applications.inception_v3.preprocess_input(inceptionV3_inputs)\n",
    "\n",
    "inceptionV3_x = inceptionV3_base_model(inceptionV3_x)\n",
    "\n",
    "inceptionV3_x = GlobalAveragePooling2D()(inceptionV3_x)\n",
    "\n",
    "inceptionV3_outputs = Dense(3, activation = 'softmax')(inceptionV3_x)\n",
    "\n",
    "inceptionV3_model = Model(inceptionV3_inputs, inceptionV3_outputs)\n",
    "\n",
    "inceptionV3_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0668dd-fd7e-44ab-be19-400875b1ab9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(inceptionV3_base_model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820e1edd-8054-4107-98fb-1868d54043cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "tf.keras.utils.plot_model(\n",
    "    inceptionV3_model,\n",
    "    to_file = 'InceptionV3.png',\n",
    "    show_shapes = True,\n",
    "    show_dtype = False,\n",
    "    show_layer_names = False,\n",
    "    show_layer_activations = True,\n",
    "    expand_nested = True\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9d9656-10e7-465d-8736-e36961c35efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "inceptionV3_model.compile(loss = 'sparse_categorical_crossentropy',\n",
    "              optimizer = Adam(learning_rate = 0.001),\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623aa9ec-228d-43eb-a15e-382595132d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "inceptionV3_history = inceptionV3_model.fit(X_train, y_train, epochs = EPOCHS, validation_data = (X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd6fa16-be43-4ae8-800a-ffe0b6eec521",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = inceptionV3_history.history['accuracy']\n",
    "val_acc = inceptionV3_history.history['val_accuracy']\n",
    "\n",
    "loss = inceptionV3_history.history['loss']\n",
    "val_loss = inceptionV3_history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0fc81f-52a7-464d-9da9-6d76f16b4d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy_loss(inceptionV3_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ed2763-0ccd-4c39-91a0-f2c2352fc255",
   "metadata": {},
   "source": [
    "#### Unfreeze and Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d9f4b6-316c-42ed-ab6a-9e192f7daf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inceptionV3_base_model.trainable = True\n",
    "for layer in inceptionV3_base_model.layers[:-50]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44fcf7b-b8ad-48d2-9cc2-708348600800",
   "metadata": {},
   "outputs": [],
   "source": [
    "inceptionV3_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4989ffcf-9a79-4bcf-986e-9e6a9cff520f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inceptionV3_model.compile(loss = 'sparse_categorical_crossentropy',\n",
    "                          optimizer = Adam(learning_rate = 0.0001),\n",
    "                          metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1f479a-e37a-4a53-b208-28dad7eed179",
   "metadata": {},
   "outputs": [],
   "source": [
    "inceptionV3_history_fine = inceptionV3_model.fit(X_train, y_train, epochs = EPOCHS * 2, initial_epoch = EPOCHS, validation_data = (X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875c2b3d-b189-48ab-8c5a-be4932f10829",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc += inceptionV3_history_fine.history['accuracy']\n",
    "val_acc += inceptionV3_history_fine.history['val_accuracy']\n",
    "\n",
    "loss += inceptionV3_history_fine.history['loss']\n",
    "val_loss += inceptionV3_history_fine.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500d4bc3-99c2-4dc1-a17d-4d10c30be257",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.plot([EPOCHS-1,EPOCHS-1],\n",
    "          plt.ylim(), label='Start Fine Tuning')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.plot([EPOCHS-1,EPOCHS-1],\n",
    "         plt.ylim(), label='Start Fine Tuning')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.grid(True)\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73581a3c-dbcf-4ff2-8c82-4a43f032aa54",
   "metadata": {},
   "source": [
    "#### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3006fa-4855-48d7-a224-cfeece2286c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "inceptionV3_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c68e7f6-17ea-46dd-b5c7-65d81133fa4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_probs = inceptionV3_model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9163c206-f06c-49cd-8947-43be0b3cc558",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc9fbfd-70e1-4c93-96fb-d9f7a8396b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=class_names,\n",
    "            yticklabels=class_names)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15297ea-b248-4e87-bb0e-f6fcec14da98",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = len(class_names)\n",
    "\n",
    "y_score = inceptionV3_model.predict(X_test)\n",
    "\n",
    "y_test_bin = label_binarize(y_test, classes=np.arange(n_classes))\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    if np.sum(y_test_bin[:, i]) == 0:\n",
    "        print(f\"Skipping class {i} ({class_names[i]}): no positive samples in y_test.\")\n",
    "        continue\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i, color in zip(roc_auc, colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(class_names[i], roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([-0.05, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Multi-class ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372cf229-374b-40c9-bbb1-37034f839bbb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### DenseNet201"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc0deeb-f202-42b6-8f5d-cd01680985b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "denseNet201_base_model = DenseNet201(include_top = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573487a1-54d2-4817-9400-0c4df29212d5",
   "metadata": {},
   "source": [
    "#### Freeze and Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2a3a3e-dceb-400a-8afe-a0abfad68255",
   "metadata": {},
   "outputs": [],
   "source": [
    "denseNet201_base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7860e97f-02f9-403c-91d8-9dd1d7166056",
   "metadata": {},
   "outputs": [],
   "source": [
    "denseNet201_inputs = Input(shape = (224, 224, 3))\n",
    "\n",
    "denseNet201_x = data_augmentation(denseNet201_inputs)\n",
    "\n",
    "denseNet201_x = tf.keras.applications.densenet.preprocess_input(denseNet201_x)\n",
    "\n",
    "denseNet201_x = denseNet201_base_model(denseNet201_x)\n",
    "\n",
    "denseNet201_x = GlobalAveragePooling2D()(denseNet201_x)\n",
    "\n",
    "denseNet201_outputs = Dense(3, activation = 'softmax')(denseNet201_x)\n",
    "\n",
    "denseNet201_model = Model(denseNet201_inputs, denseNet201_outputs)\n",
    "\n",
    "denseNet201_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2429605b-6f6f-4261-b4d0-64e502fac716",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(denseNet201_base_model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a7db8b-982c-4e70-929c-a99fb2eb57f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "denseNet201_model.compile(loss = 'sparse_categorical_crossentropy',\n",
    "              optimizer = Adam(learning_rate = 0.001),\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633cd8dd-403b-402c-8900-9d5353c10f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "denseNet201_history = denseNet201_model.fit(X_train_augmented, y_train_augmented, epochs = EPOCHS, validation_data = (X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e201f15c-fe6d-430a-811c-1a97e9817807",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = denseNet201_history.history['accuracy']\n",
    "val_acc = denseNet201_history.history['val_accuracy']\n",
    "\n",
    "loss = denseNet201_history.history['loss']\n",
    "val_loss = denseNet201_history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca244afd-feb6-4512-9d0c-a4f39748ee24",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy_loss(denseNet201_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24a22dc-5542-4de4-8fc1-aabe271c4607",
   "metadata": {},
   "source": [
    "#### Unfreeze and Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22402d70-a73c-4b51-9565-4580257421a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "denseNet201_base_model.trainable = True\n",
    "for layer in denseNet201_base_model.layers[:-200]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e4a23a-c2d6-4f3e-a1fe-4d1ad90c860c",
   "metadata": {},
   "outputs": [],
   "source": [
    "denseNet201_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6554467-fa28-4d31-880a-d307e6f2aa01",
   "metadata": {},
   "outputs": [],
   "source": [
    "denseNet201_model.compile(loss = 'sparse_categorical_crossentropy',\n",
    "                          optimizer = Adam(learning_rate = 0.0001),\n",
    "                          metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2369e09c-22af-4338-b7df-2635fc5b9624",
   "metadata": {},
   "outputs": [],
   "source": [
    "denseNet201_history_fine = denseNet201_model.fit(X_train_augmented, y_train_augmented, epochs = EPOCHS * 2, initial_epoch = EPOCHS, validation_data = (X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f098972b-e166-46f8-a09e-23d9c5f99aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc += denseNet201_history_fine.history['accuracy']\n",
    "val_acc += denseNet201_history_fine.history['val_accuracy']\n",
    "\n",
    "loss += denseNet201_history_fine.history['loss']\n",
    "val_loss += denseNet201_history_fine.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d585a89d-ca77-4440-a244-728ce8ee20dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.plot([EPOCHS-1,EPOCHS-1],\n",
    "          plt.ylim(), label='Start Fine Tuning')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.plot([EPOCHS-1,EPOCHS-1],\n",
    "         plt.ylim(), label='Start Fine Tuning')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.grid(True)\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f9d95d-6247-4593-a191-2087ac01b194",
   "metadata": {},
   "source": [
    "#### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23cbf02-75ab-4644-911c-35c0fa977540",
   "metadata": {},
   "outputs": [],
   "source": [
    "denseNet201_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e8b4b1-88c7-406e-8cc5-2b8771661a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_probs = denseNet201_model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a51655d-8a9a-4495-8b93-8438fb99bea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae9d059-c24f-4353-a339-e1abe9e58662",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=class_names,\n",
    "            yticklabels=class_names)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f41ccb9-5eb9-4e0c-9b28-efe9345dfd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = len(class_names)\n",
    "\n",
    "y_score = denseNet201_model.predict(X_test)\n",
    "\n",
    "y_test_bin = label_binarize(y_test, classes=np.arange(n_classes))\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    if np.sum(y_test_bin[:, i]) == 0:\n",
    "        print(f\"Skipping class {i} ({class_names[i]}): no positive samples in y_test.\")\n",
    "        continue\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i, color in zip(roc_auc, colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(class_names[i], roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([-0.05, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Multi-class ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f21b5b9-6a6c-4115-9d68-0fad66772613",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4048ed-2a9c-496f-abf2-2eebefd3634d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mobileNetV2_base_model = MobileNetV2(input_shape = (224, 224, 3), include_top = False, weights = 'imagenet')\n",
    "mobileNetV2_base_model.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c150b422-6d04-4f75-9962-28f0e357a98b",
   "metadata": {},
   "source": [
    "#### Freeze and Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1544502-cc45-49f0-aa32-363842c99af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mobileNetV2_inputs = Input(shape = (224, 224, 3))\n",
    "\n",
    "mobileNetV2_x = data_augmentation(mobileNetV2_inputs)\n",
    "\n",
    "mobileNetV2_x = tf.keras.applications.mobilenet_v2.preprocess_input(mobileNetV2_x)\n",
    "\n",
    "mobileNetV2_x = mobileNetV2_base_model(mobileNetV2_x)\n",
    "\n",
    "mobileNetV2_x = GlobalAveragePooling2D()(mobileNetV2_x)\n",
    "\n",
    "mobileNetV2_outputs = Dense(3, activation = 'softmax')(mobileNetV2_x)\n",
    "\n",
    "mobileNetV2_model = Model(mobileNetV2_inputs, mobileNetV2_outputs)\n",
    "\n",
    "mobileNetV2_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba81e19-e22c-46df-abe6-a6a163caff00",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mobileNetV2_base_model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed561ba-da5d-4b82-971a-eb5556b298d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "tf.keras.utils.plot_model(\n",
    "    mobileNetV2_model,\n",
    "    to_file = 'MobileNetV2.png',\n",
    "    show_shapes = True,\n",
    "    show_dtype = False,\n",
    "    show_layer_names = False,\n",
    "    show_layer_activations = True,\n",
    "    expand_nested = True\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18407cb0-cffb-4195-9683-815023f13dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "mobileNetV2_model.compile(loss = 'sparse_categorical_crossentropy',\n",
    "              optimizer = Adam(learning_rate = 0.001),\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493a90d2-aab5-4fa7-9ac4-083e3586dfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mobileNetV2_history = mobileNetV2_model.fit(X_train_augmented, y_train_augmented, epochs = EPOCHS, validation_data = (X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da55f4f3-a886-4f81-9eda-7cc56172b78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = mobileNetV2_history.history['accuracy']\n",
    "val_acc = mobileNetV2_history.history['val_accuracy']\n",
    "\n",
    "loss = mobileNetV2_history.history['loss']\n",
    "val_loss = mobileNetV2_history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869ed698-dc19-4c1c-8e0d-7cce4f160fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy_loss(mobileNetV2_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16834ae8-cd7e-4e59-819b-c6af941072aa",
   "metadata": {},
   "source": [
    "#### Unfreeze and Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc985a60-dc16-4db8-bcbf-3b347e49fa61",
   "metadata": {},
   "outputs": [],
   "source": [
    "mobileNetV2_base_model.trainable = True\n",
    "for layer in mobileNetV2_base_model.layers[:-5]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2492b3c-7102-49f2-8234-2778c5b8fac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mobileNetV2_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cdee20-d29c-4368-8d7a-fd81a85a9be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mobileNetV2_model.compile(loss = 'sparse_categorical_crossentropy',\n",
    "                          optimizer = Adam(learning_rate = 0.0001),\n",
    "                          metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89799a2-9eb6-4781-84c1-90d043c436ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "mobileNetV2_history_fine = mobileNetV2_model.fit(X_train_augmented, y_train_augmented, epochs = EPOCHS * 2, initial_epoch = EPOCHS, validation_data = (X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342c00ce-3477-44ba-a862-4207f53f02fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc += mobileNetV2_history_fine.history['accuracy']\n",
    "val_acc += mobileNetV2_history_fine.history['val_accuracy']\n",
    "\n",
    "loss += mobileNetV2_history_fine.history['loss']\n",
    "val_loss += mobileNetV2_history_fine.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e68a0b3-c81f-4074-8bfe-068e09866e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.plot([EPOCHS-1,EPOCHS-1],\n",
    "          plt.ylim(), label='Start Fine Tuning')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.plot([EPOCHS-1,EPOCHS-1],\n",
    "         plt.ylim(), label='Start Fine Tuning')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.grid(True)\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3d5bb0-af56-4474-b7c5-801a38bdcd8e",
   "metadata": {},
   "source": [
    "#### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cd16ab-a26a-4bf2-a02a-0c5430af70a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mobileNetV2_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdb33d1-4677-4225-a129-38832d7fa520",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_probs = mobileNetV2_model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32a37ee-01ee-42d3-8673-3c5ab95ce1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b63af6-8f42-4af0-9bcb-b118ef83a9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=class_names,\n",
    "            yticklabels=class_names)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5726b0e4-07f1-4f83-9d4f-417f9b555dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = len(class_names)\n",
    "\n",
    "y_score = mobileNetV2_model.predict(X_test)\n",
    "\n",
    "y_test_bin = label_binarize(y_test, classes=np.arange(n_classes))\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    if np.sum(y_test_bin[:, i]) == 0:\n",
    "        print(f\"Skipping class {i} ({class_names[i]}): no positive samples in y_test.\")\n",
    "        continue\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i, color in zip(roc_auc, colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(class_names[i], roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([-0.05, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Multi-class ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2fc254-d041-40c5-8870-3aff48737e05",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### EfficientNetV2B0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebcdd35-f3bc-4e84-b412-0e4de1bcaf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "efficientNetV2B0_base_model = EfficientNetV2B0(include_top = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038c095e-8a29-4947-b323-f3050deb0a5e",
   "metadata": {},
   "source": [
    "#### Freeze and Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cb4142-b488-411d-8213-ecfab61eae61",
   "metadata": {},
   "outputs": [],
   "source": [
    "efficientNetV2B0_base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f651d36-1acd-4a7f-bad7-ddd77706ac03",
   "metadata": {},
   "outputs": [],
   "source": [
    "efficientNetV2B0_inputs = Input(shape = (224, 224, 3))\n",
    "\n",
    "efficientNetV2B0_x = data_augmentation(efficientNetV2B0_inputs)\n",
    "\n",
    "efficientNetV2B0_x = tf.keras.applications.efficientnet_v2.preprocess_input(efficientNetV2B0_x)\n",
    "\n",
    "efficientNetV2B0_x = efficientNetV2B0_base_model(efficientNetV2B0_x)\n",
    "\n",
    "efficientNetV2B0_x = GlobalAveragePooling2D()(efficientNetV2B0_x)\n",
    "\n",
    "efficientNetV2B0_outputs = Dense(3, activation = 'softmax')(efficientNetV2B0_x)\n",
    "\n",
    "efficientNetV2B0_model = Model(efficientNetV2B0_inputs, efficientNetV2B0_outputs)\n",
    "\n",
    "efficientNetV2B0_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a3787b-5b40-4ed3-b8f4-b9a0ce86b207",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(efficientNetV2B0_base_model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df0c9ae-1205-47b9-8f5b-09929dae0ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "efficientNetV2B0_model.compile(loss = 'sparse_categorical_crossentropy',\n",
    "              optimizer = Adam(learning_rate = 0.001),\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9647e0a8-8373-47a0-9425-946a26f503c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "efficientNetV2B0_history = efficientNetV2B0_model.fit(X_train_augmented, y_train_augmented, epochs = EPOCHS, validation_data = (X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05ae0a9-bb7f-45b8-b940-9f32ee9fa9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = efficientNetV2B0_history.history['accuracy']\n",
    "val_acc = efficientNetV2B0_history.history['val_accuracy']\n",
    "\n",
    "loss = efficientNetV2B0_history.history['loss']\n",
    "val_loss = efficientNetV2B0_history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7548458f-bcce-4406-8a30-f95da53f1f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy_loss(efficientNetV2B0_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a945556-04e6-4ebe-b034-9bd70f1abae6",
   "metadata": {},
   "source": [
    "#### Unfreeze and Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d882d26b-e8b4-4489-9512-35eec63c46ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "efficientNetV2B0_base_model.trainable = True\n",
    "for layer in efficientNetV2B0_base_model.layers[:-50]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2eec32-582e-47db-b42a-d86dea964293",
   "metadata": {},
   "outputs": [],
   "source": [
    "efficientNetV2B0_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d239d5-f4f9-4639-99d7-143a1a2828bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "efficientNetV2B0_model.compile(loss = 'sparse_categorical_crossentropy',\n",
    "                          optimizer = Adam(learning_rate = 0.0001),\n",
    "                          metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f01821-b9ed-40ce-920d-836b9a92caff",
   "metadata": {},
   "outputs": [],
   "source": [
    "efficientNetV2B0_history_fine = efficientNetV2B0_model.fit(X_train_augmented, y_train_augmented, epochs = EPOCHS * 2, initial_epoch = EPOCHS, validation_data = (X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4dbc51-0b4b-4e89-8832-c8085d71dfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc += efficientNetV2B0_history_fine.history['accuracy']\n",
    "val_acc += efficientNetV2B0_history_fine.history['val_accuracy']\n",
    "\n",
    "loss += efficientNetV2B0_history_fine.history['loss']\n",
    "val_loss += efficientNetV2B0_history_fine.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de5ba50-97eb-45b4-bb92-5b80f0378fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.plot([EPOCHS-1,EPOCHS-1],\n",
    "          plt.ylim(), label='Start Fine Tuning')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.plot([EPOCHS-1,EPOCHS-1],\n",
    "         plt.ylim(), label='Start Fine Tuning')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.grid(True)\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc25858-0d2d-405a-a803-9cbaf229dea8",
   "metadata": {},
   "source": [
    "#### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a658adb-18f0-4670-96ee-b4774efd40fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "efficientNetV2B0_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e734ceb-af2b-4936-8502-c45eeec013a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_probs = efficientNetV2B0_model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f290643d-6506-4c08-9819-b8f4c7501527",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2b2c5d-2359-4bbf-af1e-7691b0cd80fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=class_names,\n",
    "            yticklabels=class_names)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0211644a-e9d9-4d39-aeac-b88d71f9137d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = len(class_names)\n",
    "\n",
    "y_score = efficientNetV2B0_model.predict(X_test)\n",
    "\n",
    "y_test_bin = label_binarize(y_test, classes=np.arange(n_classes))\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    if np.sum(y_test_bin[:, i]) == 0:\n",
    "        print(f\"Skipping class {i} ({class_names[i]}): no positive samples in y_test.\")\n",
    "        continue\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i, color in zip(roc_auc, colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(class_names[i], roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([-0.05, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Multi-class ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0dd347b-f8c8-44a6-8013-716a740f5ef2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### ResNet50V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d47a50-7bf2-4176-84f1-b6c8fea7fb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "resNet50V2_base_model = ResNet50V2(include_top = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247f0cd9-2df5-4a6c-bb2d-9aaa81137b88",
   "metadata": {},
   "source": [
    "#### Freeze and Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7626c425-0dcb-413d-8413-a1ec3057b436",
   "metadata": {},
   "outputs": [],
   "source": [
    "resNet50V2_base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f888af-88ef-4326-bb8e-65e37ff4be61",
   "metadata": {},
   "outputs": [],
   "source": [
    "resNet50V2_inputs = Input(shape = (224, 224, 3))\n",
    "\n",
    "resNet50V2_x = data_augmentation(resNet50V2_inputs)\n",
    "\n",
    "resNet50V2_x = tf.keras.applications.resnet_v2.preprocess_input(resNet50V2_x)\n",
    "\n",
    "resNet50V2_x = resNet50V2_base_model(resNet50V2_x)\n",
    "\n",
    "resNet50V2_x = GlobalAveragePooling2D()(resNet50V2_x)\n",
    "\n",
    "resNet50V2_outputs = Dense(3, activation = 'softmax')(resNet50V2_x)\n",
    "\n",
    "resNet50V2_model = Model(resNet50V2_inputs, resNet50V2_outputs)\n",
    "\n",
    "resNet50V2_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28176ee-8238-4828-9e34-bdf93a340c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(resNet50V2_base_model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e1df29-32eb-4421-83b0-633317bb4fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "resNet50V2_model.compile(loss = 'sparse_categorical_crossentropy',\n",
    "              optimizer = Adam(learning_rate = 0.001),\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ace5159-00bb-452a-a78c-85e5c5a5c6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "resNet50V2_history = resNet50V2_model.fit(X_train_augmented, y_train_augmented, epochs = EPOCHS, validation_data = (X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1019b688-1b46-4135-89c2-e322a3a88a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = resNet50V2_history.history['accuracy']\n",
    "val_acc = resNet50V2_history.history['val_accuracy']\n",
    "\n",
    "loss = resNet50V2_history.history['loss']\n",
    "val_loss = resNet50V2_history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41f9a42-e6a1-4746-9043-f62a0d4c4324",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy_loss(resNet50V2_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5030c4ae-9f70-4cf9-8287-baa2bff80e08",
   "metadata": {},
   "source": [
    "#### Unfreeze and Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd15e7e-fff5-4e74-bc7c-aab7e8689a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "resNet50V2_base_model.trainable = True\n",
    "for layer in resNet50V2_base_model.layers[:-20]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca3c344-b892-45a5-8bcb-9c98485d68a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "resNet50V2_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d1db3b-b555-4f79-a166-72e83fd63d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "resNet50V2_model.compile(loss = 'sparse_categorical_crossentropy',\n",
    "                          optimizer = Adam(learning_rate = 0.0001),\n",
    "                          metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076d6e9d-a4b8-481a-8796-622784f4fe77",
   "metadata": {},
   "outputs": [],
   "source": [
    "resNet50V2_history_fine = resNet50V2_model.fit(X_train_augmented, y_train_augmented, epochs = EPOCHS * 2, initial_epoch = EPOCHS, validation_data = (X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c5b312-d9ff-4d3e-883c-6f000a1139c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc += resNet50V2_history_fine.history['accuracy']\n",
    "val_acc += resNet50V2_history_fine.history['val_accuracy']\n",
    "\n",
    "loss += resNet50V2_history_fine.history['loss']\n",
    "val_loss += resNet50V2_history_fine.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2875072c-f462-44c2-aa21-a26e3688b84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.plot([EPOCHS-1,EPOCHS-1],\n",
    "          plt.ylim(), label='Start Fine Tuning')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.plot([EPOCHS-1,EPOCHS-1],\n",
    "         plt.ylim(), label='Start Fine Tuning')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.grid(True)\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12486bd7-0a65-4554-bb26-9ea69673c7c0",
   "metadata": {},
   "source": [
    "#### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b980b709-dca3-492d-bcf2-f0e1a1270979",
   "metadata": {},
   "outputs": [],
   "source": [
    "resNet50V2_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4994c8f-8358-41f2-93b0-5ab62d419bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_probs = resNet50V2_model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10183dc4-09e1-440e-90c6-0147fa02505a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3144ccd-cc88-4b30-9f52-b4ce51beed71",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=class_names,\n",
    "            yticklabels=class_names)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ef095a-114b-4f6a-9834-506e4148327b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = len(class_names)\n",
    "\n",
    "y_score = resNet50V2_model.predict(X_test)\n",
    "\n",
    "y_test_bin = label_binarize(y_test, classes=np.arange(n_classes))\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    if np.sum(y_test_bin[:, i]) == 0:\n",
    "        print(f\"Skipping class {i} ({class_names[i]}): no positive samples in y_test.\")\n",
    "        continue\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i, color in zip(roc_auc, colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(class_names[i], roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([-0.05, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Multi-class ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c70e579-b569-429f-a36f-f3b60b149dcf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50ff657-e527-417c-9a8e-8365f6d34420",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_base_model = VGG16(include_top = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce71a16-f881-4881-8b0d-ceb8a217b432",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c07bbb-cecf-43e3-acae-1539c1f04e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_inputs = Input(shape = (224, 224, 3))\n",
    "\n",
    "vgg16_x = data_augmentation(vgg16_inputs)\n",
    "\n",
    "vgg16_x = tf.keras.applications.vgg16.preprocess_input(vgg16_x)\n",
    "\n",
    "vgg16_x = vgg16_base_model(vgg16_x)\n",
    "\n",
    "vgg16_x = GlobalAveragePooling2D()(vgg16_x)\n",
    "\n",
    "vgg16_outputs = Dense(3, activation = 'softmax')(vgg16_x)\n",
    "\n",
    "vgg16_model = Model(vgg16_inputs, vgg16_outputs)\n",
    "\n",
    "vgg16_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80df9a75-5cf3-48ef-97d6-73dd9f5e6194",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vgg16_base_model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71710ddf-ff40-419c-a1d0-b8ee70fcc58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_model.compile(loss = 'sparse_categorical_crossentropy',\n",
    "              optimizer = Adam(learning_rate = 0.001),\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48531e45-cccd-45e3-95a7-7dc34ddb2a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_history = vgg16_model.fit(X_train_augmented, y_train_augmented, epochs = EPOCHS, validation_data = (X_val, y_val), batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0dde7a-363e-4d80-a79f-33794435c328",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = vgg16_history.history['accuracy']\n",
    "val_acc = vgg16_history.history['val_accuracy']\n",
    "\n",
    "loss = vgg16_history.history['loss']\n",
    "val_loss = vgg16_history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ad42de-506f-4ac9-bcdc-9ef6a914056f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy_loss(vgg16_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9600d7-cec5-495e-b454-4b79b29d606f",
   "metadata": {},
   "source": [
    "#### Unfreeze and Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb67818d-b1af-4bf0-9272-4e561e10cc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_base_model.trainable = True\n",
    "for layer in vgg16_base_model.layers[:-5]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabaeb2d-957d-44dd-979b-43bcb38b6857",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d83886-1a5c-485a-b63e-e9a0bdb8f5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_model.compile(loss = 'sparse_categorical_crossentropy',\n",
    "                          optimizer = Adam(learning_rate = 0.0001),\n",
    "                          metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede8bcf1-c3f1-4725-b483-667502e52635",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_history_fine = vgg16_model.fit(X_train_augmented, y_train_augmented, epochs = EPOCHS * 2, initial_epoch = EPOCHS, validation_data = (X_val, y_val), batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd31ae2-9ece-4f76-92e5-e31ef3935bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc += vgg16_history_fine.history['accuracy']\n",
    "val_acc += vgg16_history_fine.history['val_accuracy']\n",
    "\n",
    "loss += vgg16_history_fine.history['loss']\n",
    "val_loss += vgg16_history_fine.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc93cee5-351c-40db-b060-80ed7e84a071",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.plot([EPOCHS-1,EPOCHS-1],\n",
    "          plt.ylim(), label='Start Fine Tuning')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.plot([EPOCHS-1,EPOCHS-1],\n",
    "         plt.ylim(), label='Start Fine Tuning')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.grid(True)\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e9a835-3889-4684-95f4-8ddd144c79b7",
   "metadata": {},
   "source": [
    "#### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4883d8-e30d-4868-a041-63a710a2d038",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_model.evaluate(X_test, y_test, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d12322-d856-47b5-927f-cf1dc8134d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_probs = vgg16_model.predict(X_test, batch_size=8)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2d3bd1-d70c-464f-bdcb-6eaacd8a7779",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1030f9c8-48a0-4cbb-be80-55e94add1c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=class_names,\n",
    "            yticklabels=class_names)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfc09c8-0dd8-4f59-a96d-a3606f2e4dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = len(class_names)\n",
    "\n",
    "y_score = vgg16_model.predict(X_test, batch_size=8)\n",
    "\n",
    "y_test_bin = label_binarize(y_test, classes=np.arange(n_classes))\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    if np.sum(y_test_bin[:, i]) == 0:\n",
    "        print(f\"Skipping class {i} ({class_names[i]}): no positive samples in y_test.\")\n",
    "        continue\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i, color in zip(roc_auc, colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(class_names[i], roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([-0.05, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Multi-class ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59345ea0-34bc-472f-9642-b94ad4fc6cc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
